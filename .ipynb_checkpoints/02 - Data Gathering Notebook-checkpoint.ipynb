{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Data\n",
    "\n",
    "The data for this project was collected from basketball-reference.com.  Each player that played in at least one game of a season has both a game log page and an advanced game log page displaying their stats from every game they participated in.  Each team has a game log and advanced game log page as well.  The code below is meant to scrape all the data from each of player and team pages as well as clean and process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping the team data\n",
    "\n",
    "I'll be using the 2017 - 2018 season as the example in this notebook.  But this process was applied to each season beginning with the 2014-2015 season and continuing through to the current day of the current season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup  #the webscraping module\n",
    "import requests                #for accessing the sites to be scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "I am just focusing on the advanced stats\n",
    "for each team, and this will grab those stats\n",
    "from any team page that is input to the function\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def team_adv(url):\n",
    "    url = url\n",
    "    res = requests.get(url)\n",
    "    #make sure there isn't an error accessing the site \n",
    "    #200 means the request was succesful\n",
    "    if res.status_code == 200:\n",
    "        soup = BeautifulSoup(res.content, 'lxml')\n",
    "        \n",
    "        #set up an empty list for the column names\n",
    "        col_names = []\n",
    "        #this returns headers for all relevant columns\n",
    "        for i in range(9, 36):   \n",
    "            col_names.append(soup.find_all('table')[0]('thead')[0]('th')[i].text)\n",
    "    \n",
    "    #if there is a status error this will let us know\n",
    "    #400 means it is a problem with the url the user entered\n",
    "    #500 means the site is experiencing problems\n",
    "    else:\n",
    "        print('There was a ' + str(res.status_code + ' error'))\n",
    "    row = []\n",
    "    num_rows = len(soup.find_all('table')[0]('tbody')[0]('tr'))\n",
    "    num_cols = len(soup.find_all('table')[0]('tbody')[0]('tr')[0]('td'))\n",
    "    \n",
    "    #this code returns all of the statistics that belong in each column\n",
    "    for x in range(num_rows):\n",
    "        for y in range(num_cols):\n",
    "            \n",
    "            #this if statement makes sure the code doesn't break when it \n",
    "            #gets to a line that doesn't have any stats in it\n",
    "            if len(soup.find_all('table')[0]('tbody')[0]('tr')[x]('td')) == num_cols:\n",
    "                row.append(soup.find_all('table')[0]('tbody')[0]('tr')[x]('td')[y].text)\n",
    "            else:\n",
    "                pass\n",
    "    #right now the data is in one long list and needs\n",
    "    #to be broken up into rows\n",
    "    \n",
    "    rows = []\n",
    "    data = len(row)\n",
    "    b = 0  #this is a counter for when we get to the end of a row\n",
    "    for a in range(int(data / num_cols)):\n",
    "        rows.append(row[b:(b + num_cols)])\n",
    "        b += num_cols\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=col_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "This function is going to clean the data set\n",
    "that the previous function returns.  The first time this \n",
    "function is run, the only input necessary is the team abbreviation \n",
    "of the first team.  After that, each team can be passed into this\n",
    "and be concatenated on the 0 axis until we have a dataframe that\n",
    "includes all 30 teams\n",
    "\n",
    "\"\"\"\n",
    "def clean_team_adv(df, team):\n",
    "    #run the above function on the selected team's game log page\n",
    "    team = team_adv('https://www.basketball-reference.com/teams/' + team + '/2018/gamelog-advanced/')\n",
    "    \n",
    "    #rename the second column to reflect whether this team was\n",
    "    #the home team\n",
    "    team.rename(columns = {list(team)[2]: 'Home'}, inplace = True)\n",
    "    \n",
    "    #this line will take care of the problem that this dataframe has \n",
    "    #multiple columns with the same name\n",
    "    cols = []\n",
    "    count = 1\n",
    "    for column in team.columns:\n",
    "        if column == 'Opp':\n",
    "            cols.append('Opp_'+str(count))\n",
    "            count+=1\n",
    "            continue\n",
    "        elif column == 'TOV%':\n",
    "            cols.append('TOV%_'+str(count))\n",
    "            count+=1\n",
    "            continue\n",
    "        elif column == 'eFG%':\n",
    "            cols.append('eFG%_'+str(count))\n",
    "            count+=1\n",
    "            continue\n",
    "        elif column == 'Home':\n",
    "            cols.append('Home_'+str(count))\n",
    "            count+=1\n",
    "            continue\n",
    "        elif column == 'FT/FGA':\n",
    "            cols.append('FT/FGA_'+str(count))\n",
    "            count+=1\n",
    "            continue\n",
    "        cols.append(column)\n",
    "        \n",
    "    team.columns = cols\n",
    "    #renaming the rest of the columns to be more appropriately descriptive\n",
    "    team.rename(columns={'Opp_2': 'opp',\n",
    "                        'Opp_3': 'opp_score',\n",
    "                        'Tm': 'score',\n",
    "                        'W/L': 'win',\n",
    "                        'eFG%_5': 'o_efg_pct',\n",
    "                        'eFG%_9': 'd_efg_pct',\n",
    "                        'TOV%_6': 'o_tov_pct',\n",
    "                        'TOV%_10': 'd_tov_pct',\n",
    "                        'Home_1': 'Home',\n",
    "                        'FT/FGA_7': 'o_ft_fga',\n",
    "                        'FT/FGA_11': 'd_ft_fga'}, inplace=True)\n",
    "    \n",
    "    #lowercase every column and connect multiple words\n",
    "    #with an underscore. also replace certain characters\n",
    "    team.columns = [x.lower().replace('%', '_pct') for x in team.columns]\n",
    "    team.columns = [x.lower().replace('/', '_') for x in team.columns]\n",
    "    \n",
    "    #make the index of the dataframe the date of the game\n",
    "    #and drop unneccesary colums\n",
    "    team.index = team.date\n",
    "    team.drop(columns=['g', 'date', 'home_4', 'home_8'], inplace=True)\n",
    "    \n",
    "    #changing the home and win columns to binary\n",
    "    team.home = team.home.map(lambda x: 0 if x in ['@'] else 1)\n",
    "    team.win = team.win.map(lambda x: 1 if x == 'W' else 0)\n",
    "    \n",
    "    #changing the datatypes from object to integer\n",
    "    #or float where necessary\n",
    "    ints = ['score', 'opp_score']\n",
    "    floats = ['ortg', 'drtg', 'pace', 'ftr', '3par', 'ts_pct', 'trb_pct', 'ast_pct',\n",
    "              'stl_pct', 'blk_pct', 'o_efg_pct', 'o_tov_pct', 'orb_pct', 'o_ft_fga', \n",
    "              'd_efg_pct','d_tov_pct', 'drb_pct', 'd_ft_fga']\n",
    "    team[ints] = team[ints].astype(int)\n",
    "    team[floats] = team[floats].astype(float)\n",
    "    \n",
    "    #this adds recursive average columns for all the relevant \n",
    "    #stats. these will end up being possible features for model\n",
    "    more_cols = ['score', 'ortg', 'drtg', 'pace',\n",
    "             'ftr', '3par', 'ts_pct', 'trb_pct',\n",
    "             'ast_pct', 'stl_pct', 'blk_pct', 'o_efg_pct',\n",
    "             'o_tov_pct', 'orb_pct', 'o_ft_fga', 'd_efg_pct',\n",
    "             'd_tov_pct', 'drb_pct', 'd_ft_fga']\n",
    "    for col in more_cols:\n",
    "        stat_list = list(team[col])\n",
    "        avg = [0]\n",
    "        for i in range(1, len(stat_list)):\n",
    "            avg.append((np.sum(stat_list[:i]) / len(stat_list[:i])).round(2))\n",
    "        team['avg_' + col] = avg\n",
    "    \n",
    "    #add this team data set to all the previous ones\n",
    "    adv_df = pd.concat([df, team], axis=0)\n",
    "    #return the completely cleaned and process data\n",
    "    return adv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Player Data\n",
    "\n",
    "This requires a lot of similar steps to those used in scraping the team data.  There are three functions here.  One for the player's regular stats, one to get the advanced stats and to concatenate the two together on the 1 axis, and then a third to merge each player with the team they played against that game.  It also adds the fantasy points column as well as double doubles and triple doubles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player(url):\n",
    "    \n",
    "    url = url\n",
    "    res = requests.get(url)\n",
    "    if res.status_code == 200:\n",
    "        \n",
    "        soup = BeautifulSoup(res.content, 'lxml')\n",
    "        col_names = []\n",
    "        header = len(soup.find_all('table')[7]('thead')[0]('tr')[0]('th'))\n",
    "        for i in range(1, header):\n",
    "            col_names.append(soup.find_all('table')[7]('thead')[0]('tr')[0]('th')[i].text)\n",
    "\n",
    "        num_cols = len(col_names)\n",
    "        num_rows = len(soup.find_all('table')[7]('tbody')[0]('tr'))\n",
    "        \n",
    "    else:\n",
    "        print('There was a ' + res.status_code + ' status error')\n",
    "    row = []\n",
    "        \n",
    "    for x in range(num_rows):\n",
    "        for y in range(num_cols):\n",
    "            if len(soup.find_all('table')[7]('tbody')[0]('tr')[x]('td')) == num_cols:\n",
    "                row.append(soup.find_all('table')[7]('tbody')[0]('tr')[x]('td')[y].text)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    rows = []\n",
    "    data = len(row)\n",
    "    b = 0\n",
    "    for a in range(int(data / num_cols)):\n",
    "        rows.append(row[b:(b + num_cols)])\n",
    "        b += num_cols\n",
    "\n",
    "    player = pd.DataFrame(rows, columns=col_names)\n",
    "    return player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_adv(url):\n",
    "    \n",
    "    url = url\n",
    "    res = requests.get(url)\n",
    "    if res.status_code == 200:\n",
    "        \n",
    "        soup = BeautifulSoup(res.content, 'lxml')\n",
    "        col_names = []\n",
    "        header = len(soup.find_all('table')[0]('thead')[0]('tr')[0]('th'))\n",
    "        for i in range(10, header):\n",
    "            col_names.append(soup.find_all('table')[0]('thead')[0]('tr')[0]('th')[i].text)\n",
    "\n",
    "        num_cols = len(col_names)\n",
    "        num_rows = len(soup.find_all('table')[0]('tbody')[0]('tr'))\n",
    "        \n",
    "    else:\n",
    "        print('There was a status error')\n",
    "    row = []\n",
    "        \n",
    "    for x in range(num_rows):    \n",
    "        for y in range(9, num_cols + 9):\n",
    "            if len(soup.find_all('table')[0]('tbody')[0]('tr')[x]('td')) == 22:\n",
    "                row.append(soup.find_all('table')[0]('tbody')[0]('tr')[x]('td')[y].text)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    rows = []\n",
    "    data = len(row)\n",
    "    b = 0\n",
    "    for a in range(int(data / num_cols)):\n",
    "        rows.append(row[b:(b + num_cols)])\n",
    "        b += num_cols\n",
    "\n",
    "    player = pd.DataFrame(rows, columns=col_names)\n",
    "    return player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function takes a player's game log page and advanced game log\n",
    "page, runs the above two functions on them and concatenates them\n",
    "together.  The df input is not used for the first player, but for\n",
    "every player after so that we continue to concatenate to the bottom\n",
    "until every player's game stats are included in the dataframe\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def complete(url, url_2, name, df):\n",
    "    #run functions on the two urls and then concatenate them \n",
    "    complete_player = pd.concat([player(i), player_adv(j)], axis=1)\n",
    "    #make the index the date of the game \n",
    "    complete_player.index=complete_player['Date']\n",
    "    #renaming of columns just like with the team data\n",
    "    complete_player.rename(columns = {list(complete_player)[4]: 'Home'}, inplace = True)\n",
    "    cols = []\n",
    "    count = 1\n",
    "    for column in complete_player.columns:\n",
    "        if column == 'Home':\n",
    "            cols.append('Home_'+str(count))\n",
    "            count+=1\n",
    "            continue\n",
    "        elif column == 'GmSc':\n",
    "            cols.append('GmSc'+str(count))\n",
    "            count+=1\n",
    "            continue\n",
    "        cols.append(column)\n",
    "    complete_player.columns = cols\n",
    "\n",
    "    complete_player.rename(columns={'Home_1': 'Home',\n",
    "                                   'Home_2': 'Win_Loss',\n",
    "                                   '+/-': 'plus_minus',\n",
    "                                   'GmSc4': 'GmSc'}, inplace=True)\n",
    "    complete_player.drop(columns=['G', 'GmSc3', 'Date', 'Age'], inplace=True)\n",
    "\n",
    "    complete_player.plus_minus = [x.replace('+', '') for x in complete_player.plus_minus]\n",
    "    \n",
    "    for i in complete_player.columns:\n",
    "        complete_player[i] = complete_player[i].map(lambda x: 0.0 if len(x) == 0 else x)\n",
    "\n",
    "    \n",
    "    complete_player['MP'] = complete_player['MP'].map(lambda x: float(x.replace(':', '.')))\n",
    "    complete_player['MP'] = complete_player['MP'].map(lambda x: int(x))\n",
    "\n",
    "    complete_player.columns = [x.lower().replace('%', '_pct') for x in complete_player.columns]\n",
    "\n",
    "    complete_player.home = complete_player.home.map(lambda x: 0 if x in ['@'] else 1)\n",
    "    \n",
    "    \n",
    "    ints = ['gs', 'fg', 'fga', '3p', '3pa', 'ft', 'fta', 'orb', 'drb', 'trb', 'ast',\n",
    "           'stl', 'blk', 'tov', 'pf', 'pts', 'plus_minus', 'ortg', 'drtg']\n",
    "\n",
    "    floats = ['3p_pct', 'fg_pct', 'ft_pct', 'ts_pct', 'efg_pct', 'orb_pct', 'drb_pct', 'trb_pct',\n",
    "             'ast_pct', 'stl_pct', 'blk_pct', 'tov_pct', 'usg_pct', 'gmsc']\n",
    "\n",
    "    complete_player[ints] = complete_player[ints].astype(int)\n",
    "    complete_player[floats] = complete_player[floats].astype(float)\n",
    "\n",
    "\"\"\"\n",
    "Here is where we create the columns for the triple double and double\n",
    "double.  We also bring in the team data and add 'opp' to the beginning of each column\n",
    "to represent that this is the stats for the opposing team that each\n",
    "player faced on a given day.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    stats = ['pts', 'trb', 'ast', 'blk', 'stl']\n",
    "    complete_player['trip_dub'] = (complete_player[stats] >= 10).sum(1) >= 3\n",
    "    complete_player['dub_dub'] = (complete_player[stats] >= 10).sum(1) >= 2\n",
    "    complete_player['trip_dub'] = complete_player['trip_dub'].map(lambda x: 1 if x == True else 0)\n",
    "    complete_player['dub_dub'] = complete_player['dub_dub'].map(lambda x: 1 if x == True else 0)\n",
    "    \n",
    "    opponent = data[data['opp'] == complete_player['tm'][0]]\n",
    "    opponent = opponent.sort_index()\n",
    "    opponent.columns = [('opp_' + x) for x in opponent.columns]\n",
    "    \n",
    "    #since we are about to merge together player data and opponent data\n",
    "    #we don't need to include these redundant columns that are in both\n",
    "    #the player and team dataframes\n",
    "    skip_columns = ['home', 'opp', 'win', 'score', 'opp_score']\n",
    "    \n",
    "    cols = [col for col in opponent.columns if col not in skip_columns]\n",
    "    \n",
    "    #we are able to add the player's opponent for a particular game by\n",
    "    #merging on the date index\n",
    "    complete_player = pd.merge(complete_player,\n",
    "                               opponent[cols],\n",
    "                               left_index=True,\n",
    "                               right_index=True)\n",
    "\n",
    "    #adding the fantasy points column\n",
    "    complete_player['fantasy_points'] = (complete_player.pts) \\\n",
    "                                        + (complete_player['3p'] * .5) \\\n",
    "                                        + (complete_player.trb * 1.25) \\\n",
    "                                        + (complete_player.ast * 1.5) \\\n",
    "                                        + (complete_player.stl * 2) \\\n",
    "                                        + (complete_player.blk * 2) \\\n",
    "                                        - (complete_player.tov * .5) \\\n",
    "                                        + (complete_player.dub_dub * 1.5) \\\n",
    "                                        + (complete_player.trip_dub * 3)\n",
    "    \n",
    "    #this line of code changes puts the name of the players into\n",
    "    #the dataframe\n",
    "    complete_player.rename(columns={'tm': 'player'}, inplace=True)\n",
    "    complete_player['player'] = name\n",
    "    #this saves an individual player's data for a season\n",
    "    complete_player.to_csv('./players_17-18/' + name + '.csv')\n",
    "    #this adds the player to the combined data for all players\n",
    "    full_df = pd.concat([df, complete_player], axis = 0)\n",
    "    \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating the Process\n",
    "\n",
    "There's a page on basketball-reference.com that lists every player that played during a season.  We can pull those player names and put them in a list.  Then iterate through the list and apply the above functions to each player.  This process usually took around two and a half hours per season.  However by the end, I had over 117,000 rows to build a model with and a choice of over 60 columns to build a model with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get each player's name \n",
    "stats = 'https://www.basketball-reference.com/leagues/NBA_2018_per_game.html'\n",
    "res = requests.get(stats)\n",
    "soup = BeautifulSoup(res.content, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code will find each players name from the above page\n",
    "col_names = []\n",
    "header = len(soup.find_all('table')[0]('thead')[0]('tr')[0]('th'))\n",
    "for i in range(1, header):\n",
    "    col_names.append(soup.find_all('table')[0]('thead')[0]('tr')[0]('th')[i].text)\n",
    "\n",
    "num_cols = len(col_names)\n",
    "num_rows = len(soup.find_all('table')[0]('tbody')[0]('tr'))\n",
    "\n",
    "row = []\n",
    "        \n",
    "for x in range(num_rows):\n",
    "    if len(soup.find_all('table')[0]('tbody')[0]('tr')[x]('td')) == num_cols:\n",
    "            row.append(soup.find_all('table')[0]('tbody')[0]('tr')[x]('td')[0].text)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code makes each players name lowercase and connects\n",
    "#the first and last names with an underscore so that it can \n",
    "#be inserted into the name of a csv file\n",
    "names = [x.replace('.html', '') for x in row]\n",
    "\n",
    "#when players switch teams, they are represented in multiple\n",
    "#lines of the total players table.  the below code makes sure\n",
    "#each player goes into the names list only once\n",
    "from collections import OrderedDict\n",
    "names = list(OrderedDict.fromkeys(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the player ids from their unique url\n",
    "col_names = []\n",
    "header = len(soup.find_all('table')[0]('thead')[0]('tr')[0]('th'))\n",
    "for i in range(1, header):\n",
    "    col_names.append(soup.find_all('table')[0]('thead')[0]('tr')[0]('th')[i].text)\n",
    "\n",
    "num_cols = len(col_names)\n",
    "num_new_rows = len(soup.find_all('table')[0]('tbody')[0]('tr'))\n",
    "\n",
    "new_row = []\n",
    "        \n",
    "for x in range(num_new_rows):\n",
    "    if len(soup.find_all('table')[0]('tbody')[0]('tr')[x]('td')) == num_cols:\n",
    "            new_row.append(soup.find_all('table')[0]('tbody')[0]('tr')[x]('td')[0]('a')[0]['href'])\n",
    "    else:\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code pulls the player id off of the page so that\n",
    "#it can be added to the url template as we are looping\n",
    "#through each player to apply the above functions\n",
    "players = [x.replace('.html', '') for x in new_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the list of unique player urls to loop through\n",
    "#and apply the above functions.  first from the regular stats\n",
    "#game log page\n",
    "player_list = []\n",
    "for player in players:\n",
    "    player_list.append('https://www.basketball-reference.com' + player + '/gamelog/2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next we grab the advanced stats\n",
    "adv_player_list = []\n",
    "for player in players:\n",
    "    adv_player_list.append('https://www.basketball-reference.com' + player + '/gamelog-advanced/2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally Iterate Through All the Players\n",
    "\n",
    "Here is where we run the big functions from above on each player and add them to the full season dataframe that will include everyone that played in at least one game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the functions on the first player to get an initial dataframe\n",
    "total = complete(player_list[0], adv_player_list[0], names[0])\n",
    "\n",
    "#now that we have a player dataframe that we can concatenate all\n",
    "#the other player dataframes to, we will add the dataframe as an\n",
    "#input to the function\n",
    "for i in range(1, len(names)):\n",
    "    total = complete(player_list[i], adv_player_list[i], names[i], total)\n",
    "    #this will let us know that the cell is continuing to run by \n",
    "    #printing every time a new player dataframe has been completed\n",
    "    print(names[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worth Noting\n",
    "\n",
    "This will usually run and populate on its own.  However, if there were to be a status error during the running of the above cell, make sure to change the range in the function to start at where we left off before the error.  We will know where this is because we are printing out each player as they have been added to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
